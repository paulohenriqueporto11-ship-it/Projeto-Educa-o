// src/ia_engine/corretor.js

// =================================================================
// ‚öôÔ∏è CONFIGURA√á√ïES (CONSTANTES GLOBAIS)
// =================================================================
const CONFIG = {
    PONTOS: {
        MAX: 200,
        MIN: 0,
        PENALIDADE: {
            LEVE: 20,
            MEDIA: 40,
            GRAVE: 60,
            FATAL: 120,
            REPETICAO: 20,
            FRASE_LONGA: 10
        },
        BONUS: {
            VOCABULARIO: 20,
            ELEMENTO_C5: 40
        }
    },
    LIMITES: {
        MIN_PALAVRAS: 50,
        MIN_VOCABULARIO_UNICO: 0.35,
        FRASE_LONGA_QTD: 55,
        MAX_REPETICAO_CONECTIVO: 3,
        MIN_PARAGRAFOS: 3,
        TAMANHO_DETALHAMENTO: 150
    }
};

// =================================================================
// üìö L√âXICO & DADOS
// =================================================================
const LEXICO = {
    // Listas Simples (Palavras √önicas) -> Ser√£o convertidas em SETs para O(1)
    ORALIDADE: ['vc', 'pq', 'tb', 'pra', 'mt', 'n', 'eh', 'aki', 'naum', 'axo', 'coisa', 'neg√≥cio', 'tipo', 'a√≠', 'ent√£o', 'da√≠', 'n√©', 'ta', 't√°', 'blz', 'so'],
    VOCABULARIO_RICO: ['imprescind√≠vel', 'intr√≠nseco', 'corroborar', 'paradigma', 'utopia', 'ef√™mero', 'mitigar', 'exacerbar', 'vi√©s', 'conjuntura', 'preponderante', 'inexor√°vel', 'fomento', 'alicerce', 'consoante', 'premissa', 'an√°logo', 'disson√¢ncia', 'inerente'],
    MARCAS_OPINIAO: ['fundamental', 'imprescind√≠vel', 'urgente', 'not√≥rio', 'grave', 'deve-se', 'precisa-se', 'defende-se', 'acredita-se', 'observa-se', 'inaceit√°vel', 'crucial', 'lastim√°vel', 'preocupante'],
    CONECTIVOS_TRANSICAO: ['portanto', 'entretanto', 'contudo', 'todavia', 'al√©m', 'visto', 'dessa', 'suma', 'consequentemente', 'nesse', 'sob', 'diante', 'outrossim', 'adicionando', 'contrapartida', 'assim', 'logo', 'primeiramente', 'ademais', 'fim'],
    
    // Listas Complexas (Frases/Regex) -> Ser√£o pr√©-compiladas
    CLICHES: ['hoje em dia', 'nos dias de hoje', 'desde os prim√≥rdios', 'a cada dia que passa', 'com certeza', 'no mundo atual', 'atualmente', 'desde sempre'],
    REPERTORIO: ['segundo', 'de acordo', 'conforme', 'ibge', 'oms', 'onu', 'constitui√ß√£o', 'lei', 'artigo', 'fil√≥sofo', 'soci√≥logo', 'pensador', 'obra', 'livro', 'filme', 's√©rie', 'document√°rio', 'dados', 'estat√≠stica', 'pesquisa', 'estudo', 'universidade', 'ci√™ncia', 'hist√≥ria', 'guerra', 'revolu√ß√£o', 'cen√°rio', 'panorama', 'literatura'],
    
    // Estruturas C5
    C5_ELEMENTOS: [
        { chave: 'AGENTE', msg: 'Faltou AGENTE (Quem?)', termos: ['governo', 'estado', 'minist√©rio', 'escola', 'm√≠dia', 'sociedade', 'fam√≠lia', 'ongs', 'poder p√∫blico', 'legislativo', 'executivo', 'cabe ao', 'cabe √†', 'indiv√≠duo', 'cidad√£o'] },
        { chave: 'ACAO', msg: 'Faltou A√á√ÉO (O qu√™?)', termos: ['deve', 'precisa', 'necessita', 'cabe a', 'promover', 'criar', 'fiscalizar', 'investir', 'implementar', 'fomentar', 'realizar', 'garantir', 'desenvolver', 'elaborar', 'instituir', 'viabilizar'] },
        { chave: 'MEIO', msg: 'Faltou MEIO/MODO (Como?)', termos: ['por meio', 'atrav√©s', 'mediante', 'interm√©dio', 'uso de', 'via', 'aux√≠lio', 'partir de'] },
        { chave: 'FINALIDADE', msg: 'Faltou FINALIDADE (Para qu√™?)', termos: ['a fim', 'intuito', 'para que', 'visando', 'fito', 'objetivando', 'sentido de', 'mitigar', 'resolver', 'prop√≥sito'] }
    ],
    C5_GENERICOS: ['conscientizar', 'palestra']
};

// =================================================================
// ‚ö° CACHE DE PERFORMANCE (PR√â-COMPILA√á√ÉO)
// =================================================================
// Executado apenas UMA vez quando o servidor inicia.
const CACHE = {
    SETS: {
        ORALIDADE: new Set(LEXICO.ORALIDADE),
        VOCABULARIO_RICO: new Set(LEXICO.VOCABULARIO_RICO),
        MARCAS_OPINIAO: new Set(LEXICO.MARCAS_OPINIAO),
        CONECTIVOS: new Set(LEXICO.CONECTIVOS_TRANSICAO)
    },
    REGEX: {
        // Cria um regex gigante OR (termo1|termo2|...) para checagem r√°pida de frases
        CLICHES: new RegExp(`\\b(${LEXICO.CLICHES.join('|')})\\b`, 'gi'),
        REPERTORIO: new RegExp(`\\b(${LEXICO.REPERTORIO.join('|')})\\b`, 'gi'),
        // Gram√°tica
        PONTUACAO_ESPACO_ANTES: /\s+[.,;]/,
        PONTUACAO_FALTA_ESPACO: /[.,;][a-zA-Z]/,
        PONTO_SOLTO: /[a-z] \.[A-Z]/,
        CONCORDANCIA: /\b(os|as|uns|umas)\s+(problema|pessoa|crian√ßa|vez|cidad√£o|pa√≠s|lei|quest√£o)\b/i,
        HOUVERAM: /\bhouveram\b/i,
        FAZEM_TEMPO: /\bfazem\s+\d+\s+anos\b/i,
        CRASE_ERRO: /\b√†\s+(partir|todos|medida|mim|ti|n√≥s|ele|ela)\b/i,
        MIM_CONJUGA: /\b(mim|ti)\s+(fazer|ser|ir|ter|falar)\b/i,
        INICIO_OBLIQUO: /^\s*(me|te|se|nos|lhe)\s+[a-z]/im,
        FRASES_SPLIT: /[.!?]+/
    }
};

// =================================================================
// üõ†Ô∏è HELPERS OTIMIZADOS
// =================================================================

function normalizar(txt) {
    return txt.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "").trim();
}

function clamp(val) {
    return Math.max(CONFIG.PONTOS.MIN, Math.min(CONFIG.PONTOS.MAX, val));
}

function penalizar(comp, pontos, tipo, descricao, exemplo, acao) {
    comp.nota = clamp(comp.nota - pontos);
    // Verifica√ß√£o de unicidade otimizada
    if (!comp.erros.some(e => e.descricao === descricao)) {
        comp.erros.push({ tipo, descricao, exemplo, acao });
    }
}

function bonificar(comp, pontos) {
    comp.nota = clamp(comp.nota + pontos);
}

// Tokenizador Robusto (Gera array de palavras limpas)
function tokenizar(texto) {
    return normalizar(texto).match(/\b[\w√Ä-√ø]+\b/g) || [];
}

// Checagem de frases exatas usando Regex Pr√©-Compilado
function contemFrase(texto, regex) {
    return regex.test(texto);
}

// Checagem de palavras soltas usando SET (O(1))
function contemPalavra(tokens, setAlvo) {
    return tokens.some(t => setAlvo.has(t));
}

// Contador de frequencia usando MAP (Passagem √∫nica)
function analisarFrequencia(tokens, setAlvo) {
    const mapa = new Map();
    tokens.forEach(t => {
        if (setAlvo.has(t)) {
            mapa.set(t, (mapa.get(t) || 0) + 1);
        }
    });
    return mapa;
}

// Hash de frase para detec√ß√£o de loop (ignora pontua√ß√£o e espa√ßos)
function hashFrase(frase) {
    return normalizar(frase).replace(/[^\w]/g, '');
}

// =================================================================
// üß† M√ìDULOS DE COMPET√äNCIA
// =================================================================

function analisarC1(texto, textoLower, tokens, frases, resC1) {
    // 1. Oralidade (Uso de SET - O(1) por token)
    const oralidadesEncontradas = tokens.filter(t => CACHE.SETS.ORALIDADE.has(t));
    if (oralidadesEncontradas.length > 0) {
        const exemplo = [...new Set(oralidadesEncontradas)].slice(0, 3).join(', ');
        penalizar(resC1, CONFIG.PONTOS.PENALIDADE.LEVE, "Oralidade", "Termos informais.", `Ex: ${exemplo}`, "Use linguagem culta.");
    }

    // 2. Pontua√ß√£o e Gram√°tica (Regex Pr√©-compilados)
    const check = (regex, pontos, tipo, desc, ex, acao) => {
        if (regex.test(texto)) penalizar(resC1, pontos, tipo, desc, ex, acao);
    };

    check(CACHE.REGEX.PONTUACAO_ESPACO_ANTES, CONFIG.PONTOS.PENALIDADE.LEVE, "Pontua√ß√£o", "Espa√ßo antes de sinal.", "Ex: 'Ol√° ,'", "Remova o espa√ßo.");
    check(CACHE.REGEX.PONTUACAO_FALTA_ESPACO, CONFIG.PONTOS.PENALIDADE.LEVE, "Pontua√ß√£o", "Falta espa√ßo ap√≥s sinal.", "Ex: 'Ol√°,mundo'", "Adicione espa√ßo.");
    check(CACHE.REGEX.PONTO_SOLTO, CONFIG.PONTOS.PENALIDADE.LEVE, "Pontua√ß√£o", "Ponto final isolado.", "Ex: 'fim . Come√ßo'", "Una o ponto √† palavra.");
    check(CACHE.REGEX.CONCORDANCIA, CONFIG.PONTOS.PENALIDADE.MEDIA, "Concord√¢ncia", "Erro plural/singular.", "Ex: 'Os problema'", "Ajuste o n√∫mero.");
    check(CACHE.REGEX.HOUVERAM, CONFIG.PONTOS.PENALIDADE.MEDIA, "Gram√°tica", "Uso de 'Houveram'.", "'Houveram fatos'", "Use 'Houve'.");
    check(CACHE.REGEX.FAZEM_TEMPO, CONFIG.PONTOS.PENALIDADE.MEDIA, "Gram√°tica", "Uso de 'Fazem' (tempo).", "'Fazem anos'", "Use 'Faz anos'.");
    check(CACHE.REGEX.CRASE_ERRO, CONFIG.PONTOS.PENALIDADE.MEDIA, "Crase", "Crase indevida.", "Antes de masculino/verbo.", "Remova a crase.");
    check(CACHE.REGEX.MIM_CONJUGA, CONFIG.PONTOS.PENALIDADE.MEDIA, "Gram√°tica", "'Mim' conjuga verbo.", "'Para mim ir'", "Use 'Para eu ir'.");
    check(CACHE.REGEX.INICIO_OBLIQUO, CONFIG.PONTOS.PENALIDADE.LEVE, "Coloca√ß√£o", "In√≠cio com obl√≠quo.", "'Me ajuda'", "Use 'Ajude-me'.");

    // 3. Frases Longas
    let frasesLongas = 0;
    frases.forEach(f => {
        // Contagem aproximada por espa√ßos √© mais r√°pida que tokenizar cada frase
        if ((f.match(/\s/g) || []).length > CONFIG.LIMITES.FRASE_LONGA_QTD) frasesLongas++;
    });
    if (frasesLongas > 0) {
        penalizar(resC1, CONFIG.PONTOS.PENALIDADE.FRASE_LONGA * frasesLongas, "Fluidez", "Frases muito longas.", `${frasesLongas} per√≠odos extensos.`, "Pontue mais.");
    }

    // 4. B√¥nus Vocabul√°rio (Set O(1))
    const ricasCount = tokens.reduce((acc, t) => acc + (CACHE.SETS.VOCABULARIO_RICO.has(t) ? 1 : 0), 0);
    if (ricasCount >= 2 && resC1.nota < CONFIG.PONTOS.MAX) {
        bonificar(resC1, CONFIG.PONTOS.BONUS.VOCABULARIO);
    }
}

function analisarC2(textoLower, tema, paragrafos, resC2) {
    // 1. Tema
    if (tema && tema !== "Livre") {
        const stopWords = new Set(['a', 'o', 'e', 'do', 'da', 'de', 'em', 'para', 'com', 'que', 'um', 'uma', 'os', 'as']);
        const tokensTema = tokenizar(tema).filter(t => t.length > 3 && !stopWords.has(t));
        
        // Verifica presen√ßa (O(n*m) mas n e m s√£o pequenos aqui)
        const citacoes = tokensTema.reduce((acc, t) => acc + (textoLower.includes(t) ? 1 : 0), 0);

        if (citacoes === 0) {
            resC2.nota = 40;
            penalizar(resC2, 0, "Tema", "Fuga do tema.", `Tema: ${tema}`, "Nenhuma palavra-chave encontrada.");
        } else if (citacoes < tokensTema.length / 2) {
            penalizar(resC2, CONFIG.PONTOS.PENALIDADE.GRAVE, "Tema", "Tangenciamento.", "Tema incompleto.", "Use todos os termos do tema.");
        }
    }

    // 2. Estrutura
    if (paragrafos.length < CONFIG.LIMITES.MIN_PARAGRAFOS) {
        penalizar(resC2, CONFIG.PONTOS.PENALIDADE.FATAL, "Estrutura", "Texto insuficiente.", "Menos de 3 par√°grafos.", "Siga a estrutura dissertativa.");
    } else {
        // Monoblocos
        for (let i = 1; i < paragrafos.length - 1; i++) {
            const qtdFrases = (paragrafos[i].match(CACHE.REGEX.FRASES_SPLIT) || []).length;
            if (qtdFrases < 2) {
                penalizar(resC2, CONFIG.PONTOS.PENALIDADE.MEDIA, "Estrutura", "Par√°grafo Monobloco.", `Par√°grafo ${i+1}.`, "Divida em mais frases.");
            }
        }
        // Tese (Tokens do 1¬∫ paragrafo vs Set de Marcas)
        const tokensIntro = tokenizar(paragrafos[0]);
        if (!contemPalavra(tokensIntro, CACHE.SETS.MARCAS_OPINIAO)) {
            penalizar(resC2, CONFIG.PONTOS.PENALIDADE.MEDIA, "Tese", "Sem marca de opini√£o.", "Intro expositiva.", "Use '√© fundamental', '√© grave'.");
        }
    }
}

function analisarC3(textoLower, resC3) {
    const explicativos = ['porque', 'pois', 'visto', 'dado', 'haja'];
    const conclusivos = ['consequentemente', 'logo', 'acarreta', 'gera', 'ocasiona'];

    // Verifica√ß√£o r√°pida de substrings
    const temExpl = explicativos.some(t => textoLower.includes(t));
    const temConc = conclusivos.some(t => textoLower.includes(t));

    if (!temExpl) penalizar(resC3, CONFIG.PONTOS.PENALIDADE.MEDIA, "Argumenta√ß√£o", "Falta justificativa.", "Sem 'pois', 'visto que'.", "Explique o porqu√™.");
    if (!temConc) penalizar(resC3, CONFIG.PONTOS.PENALIDADE.MEDIA, "Aprofundamento", "Falta consequ√™ncia.", "Sem 'isso gera'.", "Mostre o impacto.");

    if (!CACHE.REGEX.REPERTORIO.test(textoLower)) {
        penalizar(resC3, CONFIG.PONTOS.PENALIDADE.GRAVE, "Repert√≥rio", "Sem repert√≥rio.", "Faltou dados/autores.", "Legitime seu argumento.");
    }

    if (CACHE.REGEX.CLICHES.test(textoLower)) {
        penalizar(resC3, CONFIG.PONTOS.PENALIDADE.LEVE, "Estilo", "Clich√™ detectado.", "Ex: 'Nos dias de hoje'", "Seja espec√≠fico.");
    }
}

function analisarC4(texto, tokens, paragrafos, resC4) {
    // Mapa de frequ√™ncia dos conectivos (Passagem √∫nica pelos tokens)
    const freqMap = analyzeConnectiveFrequency(tokens);
    const qtdUsados = freqMap.size;
    let totalConectivos = 0;

    freqMap.forEach((qtd, conectivo) => {
        totalConectivos += qtd;
        if (qtd > CONFIG.LIMITES.MAX_REPETICAO_CONECTIVO) {
            penalizar(resC4, CONFIG.PONTOS.PENALIDADE.REPETICAO_CONECTIVO, "Repeti√ß√£o", `Conectivo "${conectivo}" repetido.`, `${qtd} vezes.`, "Varie os conectivos.");
        }
    });

    if (qtdUsados < 2) penalizar(resC4, 120, "Coes√£o", "Texto desconexo.", "Poucos conectivos.", "Use conectivos.");
    else if (qtdUsados < 4) penalizar(resC4, 60, "Coes√£o", "Baixa variedade.", "Repert√≥rio limitado.", "Varie mais.");

    // Interpar√°grafos
    if (paragrafos.length > 2) {
        let conexoesInter = 0;
        const checkParagrafos = paragrafos.slice(1);
        
        checkParagrafos.forEach((p, idx) => {
            const tokensInicio = tokenizar(p.split('.')[0]); // Tokens da 1¬™ frase
            const temConectivo = tokensInicio.some(t => CACHE.SETS.CONECTIVOS.has(t));
            if (temConectivo) conexoesInter++;

            // L√≥gica Conclusiva no Desenvolvimento
            const ehConclusao = idx === checkParagrafos.length - 1;
            if (!ehConclusao && tokensInicio.some(t => ['portanto', 'concluindo', 'suma'].includes(t))) {
                penalizar(resC4, CONFIG.PONTOS.PENALIDADE.MEDIA, "L√≥gica", "Conclus√£o no desenvolvimento.", "In√≠cio com 'Portanto'.", "Use 'Ademais'.");
            }
        });

        if (conexoesInter === 0) {
            penalizar(resC4, 60, "Coes√£o", "Par√°grafos soltos.", "In√≠cios sem conectivos.", "Ligue os par√°grafos.");
        }
    }
}

// Helper espec√≠fico para C4
function analyzeConnectiveFrequency(tokens) {
    const map = new Map();
    tokens.forEach(t => {
        if (CACHE.SETS.CONECTIVOS.has(t)) {
            map.set(t, (map.get(t) || 0) + 1);
        }
    });
    return map;
}

function analisarC5(paragrafos, resC5) {
    resC5.nota = 0;
    if (paragrafos.length > 1) {
        const conclusao = normalizar(paragrafos[paragrafos.length - 1]);
        let elementos = 0;

        // Loop Din√¢mico sobre Configura√ß√£o
        LEXICO.C5_ELEMENTOS.forEach(el => {
            // Regex local simples √© r√°pido aqui pois 'termos' √© pequeno
            const regex = new RegExp(`\\b(${el.termos.join('|')})\\b`, 'i');
            if (regex.test(conclusao)) {
                elementos++;
            } else {
                penalizar(resC5, 0, "Interven√ß√£o", el.msg, `Faltou: ${el.chave}`, "Complete a proposta.");
            }
        });

        // Detalhamento
        const temExplicacao = /\b(pois|visto|ou seja|isto √©)\b/.test(conclusao);
        if (conclusao.length > CONFIG.LIMITES.TAMANHO_DETALHAMENTO && (temExplicacao || elementos >= 4)) {
            elementos++;
        } else if (elementos >= 3) {
            penalizar(resC5, 0, "Interven√ß√£o", "Faltou DETALHAMENTO.", "Proposta curta.", "Explique melhor.");
        }

        // Gen√©ricos
        if (/\b(conscientizar|palestra)\b/.test(conclusao)) {
            penalizar(resC5, 0, "Qualidade", "Interven√ß√£o Gen√©rica.", "Evite 'conscientizar'.", "A√ß√£o concreta.");
            resC5.nota = Math.min(elementos * CONFIG.PONTOS.BONUS.ELEMENTO_C5, 120);
        } else {
            resC5.nota = clamp(elementos * CONFIG.PONTOS.BONUS.ELEMENTO_C5);
        }
    } else {
        penalizar(resC5, 0, "Estrutura", "Sem conclus√£o.", "Inacabado.", "Escreva o fim.");
    }
}

// =================================================================
// üöÄ ENGINE PRINCIPAL
// =================================================================

function corrigirRedacao(texto, tema) {
    const resultado = {
        notaFinal: 0,
        competencias: {
            c1: { nome: "Norma Culta", nota: 200, erros: [] },
            c2: { nome: "Tema e Estrutura", nota: 200, erros: [] },
            c3: { nome: "Argumenta√ß√£o", nota: 200, erros: [] },
            c4: { nome: "Coes√£o", nota: 200, erros: [] },
            c5: { nome: "Proposta de Interven√ß√£o", nota: 0, erros: [] }
        },
        analiseGeral: []
    };

    const textoLimpo = texto.trim();
    if (!textoLimpo || textoLimpo.split(/\s+/).length < CONFIG.LIMITES.MIN_PALAVRAS) {
        resultado.analiseGeral.push("üö® Texto muito curto.");
        return resultado;
    }

    // ‚ö° PROCESSAMENTO √öNICO (PIPELINE)
    const textoLower = textoLimpo.toLowerCase();
    const paragrafos = textoLimpo.split(/\n+/).filter(p => p.trim().length > 0);
    const frases = textoLimpo.split(CACHE.REGEX.FRASES_SPLIT).filter(f => f.trim().length > 0);
    const tokens = tokenizar(textoLimpo); // Array de palavras limpas

    // --- SEGURAN√áA ---
    const uniqueTokens = new Set(tokens);
    if ((uniqueTokens.size / tokens.length) < CONFIG.LIMITES.MIN_VOCABULARIO_UNICO) {
        resultado.analiseGeral.push("üö® SPAM: Repeti√ß√£o excessiva.");
        return resultado;
    }
    
    // Anti-Loop com Hash
    const hashesFrases = new Set();
    const temLoop = frases.some(f => {
        if (f.length < 20) return false;
        const hash = hashFrase(f);
        if (hashesFrases.has(hash)) return true;
        hashesFrases.add(hash);
        return false;
    });
    if (temLoop) {
        resultado.analiseGeral.push("üö® SPAM: Loop de frases.");
        return resultado;
    }

    // --- EXECU√á√ÉO ---
    analisarC1(textoLimpo, textoLower, tokens, frases, resultado.competencias.c1);
    analisarC2(textoLower, tema, paragrafos, resultado.competencias.c2);
    analisarC3(textoLower, resultado.competencias.c3);
    analisarC4(textoLimpo, tokens, paragrafos, resultado.competencias.c4);
    analisarC5(paragrafos, resultado.competencias.c5);

    // Soma Final
    resultado.notaFinal = Object.values(resultado.competencias).reduce((acc, c) => acc + c.nota, 0);

    return resultado;
}

function hashFrase(frase) {
    return normalizar(frase).replace(/[^\w]/g, '');
}

module.exports = { corrigirRedacao };
